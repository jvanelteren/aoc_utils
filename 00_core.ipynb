{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp aoc\n",
    "from nbdev import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code Utils\n",
    "\n",
    "> A collection of somewhat handy functions to make your AoC puzzle life solving a bit easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections.abc import Iterable\n",
    "from collections import namedtuple, deque\n",
    "import contextlib\n",
    "import copy\n",
    "from functools import reduce\n",
    "import hashlib\n",
    "import heapq\n",
    "import logging\n",
    "from math import sqrt, gcd\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-12cdfe301294>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mDATA_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "#export \n",
    "import pickle\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "def load(filename):\n",
    "    f = open(DATA_DIR/filename,\"rb\")\n",
    "    return pickle.load(f)\n",
    "    \n",
    "def save(data, filename):\n",
    "    with open(DATA_DIR/filename, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "source": [
    "function to export files easily"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_int(inp): \n",
    "    \"\"\" \n",
    "        returns items converted to int if possible also works for tuples\\n\n",
    "        also works recursively\n",
    "        watch out because passing a string '12t' will be ripped into a list [1,2,t]\n",
    "    \"\"\"\n",
    "    if isinstance(inp,str):\n",
    "        print('watch out string will be converted into list of characters')\n",
    "    if isinstance(inp[0],list):\n",
    "        return list(to_int(l) for l in inp)\n",
    "    if isinstance(inp[0],tuple):\n",
    "        return tuple(to_int(l) for l in inp)\n",
    "\n",
    "    out = []\n",
    "    for i in inp:\n",
    "        try:\n",
    "            out.append(int(i))\n",
    "        except ValueError:\n",
    "            out.append(i)\n",
    "    if isinstance(inp,tuple): return tuple(out)\n",
    "    else: return list(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert to_int([\"12\",2,'99']) == [12, 2, 99]\n",
    "assert to_int([[[1],[2,3]],[4,5,6]]) == [[[1], [2, 3]], [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def flatten(x):\n",
    "    # recursive flattens the input. Returns a list\n",
    "    return list(_flatten(x))\n",
    "\n",
    "def _flatten(x):\n",
    "    for item in x:\n",
    "        if isinstance(item,Iterable) and not isinstance(item, str):\n",
    "            yield from flatten(item)\n",
    "        else:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert flatten([1,2,4,[99,33,[22,11]], 'f']) == [1, 2, 4, 99, 33, 22, 11, 'f']\n",
    "assert flatten([[[1],[2,3]],[4,5,6]]) == [1, 2, 3, 4, 5, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def md5(input):\n",
    "    return hashlib.md5(input.encode('utf-8')).hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'128ecf542a35ac5270a87dc740918404'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md5('bla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def arr_to_dict(arr):\n",
    "    \"\"\"\n",
    "        takes in an numpy array or list and returns a dictionary with indices, values\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(len(arr[0])):\n",
    "            d[(i,j)] = arr[i][j]\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reverse_dict(d):\n",
    "    return {v:k for k,v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {(0,0):'f'}\n",
    "a.update(reverse_dict(a))\n",
    "assert a == {(0, 0): 'f', 'f': (0, 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-bd3c0ba8cb98>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-bd3c0ba8cb98>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    elif str(path).endswith(\"tgz\"):\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def untar_data(path, save_dir = None):\n",
    "    # will untar a file to save dir or the directory of path\n",
    "    if isinstance(path,Path):\n",
    "        if str(path).endswith(\"tgz\"):\n",
    "            tar = tarfile.open(fname, \"r:gz\")\n",
    "        else:\n",
    "            tar = open(path)\n",
    "        tar.extractall(save_dir) if save_dir else tar.extractall(path.parent)\n",
    "        tar.close()\n",
    "    else:\n",
    "        print('argument should be Path instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "@contextlib.contextmanager\n",
    "def timeit(description=None):\n",
    "    # usage: with timeit('description') do what you like\n",
    "    # will output the time taken in seconds\n",
    "    tstart = time.time()\n",
    "    yield\n",
    "    elapsed = (time.time() - tstart)/60\n",
    "    logging.info(f'{description}, time: {elapsed}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data science helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def nan_inspect(df):\n",
    "    # will return some sort or correlation matrix\n",
    "    # this helps to quickly see where the na values are and if they are shared with multiple columns\n",
    "    print(df.isnull().sum(axis=1).value_counts(sort=False))\n",
    "    df_len = len(df)\n",
    "    df = df.isna().copy()\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    df = df.loc[(df!=0).any(1)]\n",
    "    df_nan_dict = {c : [len(df.loc[df[c] & df[c2]]) for c2 in df.columns] for c in df.columns}\n",
    "    df_nan = pd.DataFrame.from_dict(df_nan_dict)\n",
    "    df_nan.set_index(df.columns, inplace=True)\n",
    "    df_nan.insert(0, 'total', df_nan.max(axis=0))\n",
    "    df_nan.sort_values('total', inplace=True, ascending=False)\n",
    "    df_nan = pd.concat([df_nan['total'] , df_nan.iloc[:,1:][list(df_nan.index)]],axis=1)\n",
    "    return (df_nan/df_len).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def neighbors(i, diag = True,inc_self=False):\n",
    "    \"\"\"\n",
    "     determine the neighbors, returns a set with neighboring tuples {(0,1)}\n",
    "     if inc_self: returns self in results\n",
    "     if diag: return diagonal moves as well\n",
    "    \"\"\"\n",
    "    r = [1,0,-1]\n",
    "    c = [1,-1,0]\n",
    "    if diag:\n",
    "        if inc_self: \n",
    "            return {(i[0]+dr, i[1]+dc) for dr in r for dc in c}\n",
    "        else: \n",
    "            return {(i[0]+dr, i[1]+dc) for dr in r for dc in c if not (dr == 0 and dc == 0)}\n",
    "    else:\n",
    "        res =  {(i[0],i[1]+1), (i[0],i[1]-1),(i[0]+1,i[1]),(i[0]-1,i[1])}\n",
    "        if inc_self: res.add(i)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 and 5 tuples\n",
    "assert neighbors((0,0), inc_self=False, diag=False) == {(0, 1), (0, -1), (1, 0), (-1, 0)}\n",
    "assert neighbors((0,0), inc_self=True, diag=False) == {(0, 1), (0, -1), (1, 0), (-1, 0), (0, 0)}\n",
    "# # 8 and 9 tuples\n",
    "assert neighbors((0,0), inc_self=False, diag=True) == {(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)}\n",
    "assert neighbors((0,0), inc_self=True, diag=True) == {(1, 1), (1, -1), (1, 0), (0, 1), (0, -1), (0, 0), (-1, 1), (-1, -1), (-1, 0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def arr_neighbors(arr, diag=True, inc_self=False):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with index: set of neighbor indices\n",
    "    Parameters: diag to include diagonal neighbors, inc_self to include self in result list\n",
    "    Usage: for index, neighbor_indices in aoc.arr_neighbors(arr).items():\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for i in np.ndindex(arr.shape):\n",
    "        # print('hi',i, neighbors(i,diag))\n",
    "        res[i] = {(x,y) for x,y in neighbors(i,diag, inc_self) if 0<=x<arr.shape[0] and 0<=y<arr.shape[1]}\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n [3 4 5]\n [6 7 8]] (3, 3)\nhi (0, 0) {(0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, 0), (1, -1), (1, 1)}\nhi (0, 1) {(1, 2), (-1, 1), (0, 0), (-1, 0), (-1, 2), (1, 1), (1, 0), (0, 2)}\nhi (0, 2) {(1, 2), (0, 1), (-1, 1), (1, 3), (-1, 3), (-1, 2), (0, 3), (1, 1)}\nhi (1, 0) {(0, 1), (0, 0), (2, -1), (2, 1), (2, 0), (0, -1), (1, -1), (1, 1)}\nhi (1, 1) {(1, 2), (0, 1), (0, 0), (2, 1), (2, 0), (2, 2), (1, 0), (0, 2)}\nhi (1, 2) {(0, 1), (1, 3), (0, 2), (2, 1), (2, 3), (2, 2), (0, 3), (1, 1)}\nhi (2, 0) {(3, 0), (2, -1), (3, 1), (2, 1), (3, -1), (1, 0), (1, -1), (1, 1)}\nhi (2, 1) {(1, 2), (3, 2), (3, 0), (3, 1), (2, 0), (2, 2), (1, 0), (1, 1)}\nhi (2, 2) {(1, 2), (3, 2), (1, 3), (3, 3), (3, 1), (2, 1), (2, 3), (1, 1)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(0, 0): {(0, 1), (1, 0), (1, 1)},\n",
       " (0, 1): {(0, 0), (0, 2), (1, 0), (1, 1), (1, 2)},\n",
       " (0, 2): {(0, 1), (1, 1), (1, 2)},\n",
       " (1, 0): {(0, 0), (0, 1), (1, 1), (2, 0), (2, 1)},\n",
       " (1, 1): {(0, 0), (0, 1), (0, 2), (1, 0), (1, 2), (2, 0), (2, 1), (2, 2)},\n",
       " (1, 2): {(0, 1), (0, 2), (1, 1), (2, 1), (2, 2)},\n",
       " (2, 0): {(1, 0), (1, 1), (2, 1)},\n",
       " (2, 1): {(1, 0), (1, 1), (1, 2), (2, 0), (2, 2)},\n",
       " (2, 2): {(1, 1), (1, 2), (2, 1)}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(9).reshape(3,3).astype(object)\n",
    "print(a,a.shape)\n",
    "n = (arr_neighbors(a))\n",
    "n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "Dim = namedtuple('Dim',['min','max','range'])\n",
    "def dimensions(obj): \n",
    "    \"\"\"\n",
    "     takes an iterable of iterables and returns a namedtuple with minima, maxima and range\n",
    "     for example a 2d numpy array\n",
    "     dim.min, dim.max and dim.range\n",
    "    \"\"\"\n",
    "    minim = tuple(min(obj,key = lambda x:x[i])[i] for i in range(len(obj[0])))\n",
    "    maxim = tuple(max(obj,key = lambda x:x[i])[i] for i in range(len(obj[0])))# max for dimensions\n",
    "    ranges = tuple(maxim[i] - minim[i]  for i in range(len(obj[0])))\n",
    "    res = Dim(minim,maxim,ranges)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dimensions([[1,2,3],[10,9,8]]) == Dim(min=(1, 2, 3), max=(10, 9, 8), range=(9, 7, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = dimensions([[1,2,3],[10,9,8]])\n",
    "out.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def positive(*args): \n",
    "    \"\"\" \n",
    "        takes 1 or multiple lists of n coordinates and returns it normalized (getting rid of negatives)\n",
    "    \"\"\"\n",
    "    dtype = type(args[0][0]) # support list(s) of lists and list(s) of tuples\n",
    "    if len(args)==1: # only 1 argument passed\n",
    "        dim = dimensions(args[0])\n",
    "        obj = args[0]\n",
    "        if dtype == tuple:\n",
    "            return [tuple(o[i]-dim.min[i] for i in range(len(obj[0]))) for o in obj]\n",
    "        if dtype == list:\n",
    "            return [[o[i]-dim.min[i] for i in range(len(obj[0]))] for o in obj]\n",
    "        else: print('no support for dtype',dtype)\n",
    "    else: # multiple arguments passed\n",
    "        dim = dimensions([i for a in args for i in a])\n",
    "        if dtype == tuple:\n",
    "            return ([tuple(o[i]-dim.min[i] for i in range(len(obj[0]))) for o in obj] for obj in args)\n",
    "\n",
    "        if dtype == list: \n",
    "            return ([[o[i]-dim.min[i] for i in range(len(obj[0]))] for o in obj] for obj in args)\n",
    "        else: print('no support for dtype',dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive() will only make changes along axis where negative values are detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert positive([(0,0,0,-4),(0,0,-10,0),(0,0,0,0)]) == [(0, 0, 10, 0), (0, 0, 0, 4), (0, 0, 10, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def manhattan(x,y):\n",
    "    return abs(x[0]-y[0])+abs(x[1]-y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert manhattan((10,10),(-1,11)) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv1d(arr,conv_shape,mode='same',padding=None,pad_dir='center') ->list:\n",
    "    \"\"\"\n",
    "    Returns a list of kernel views of a string or list \n",
    "    mode == 'valid': returns only results where the kernel fits\n",
    "    mode == 'same': return the same amount of items as original\n",
    "    when mode =='same', default padding is the outer value\n",
    "    \"\"\"\n",
    "    if padding:\n",
    "        to_pad = padding # user specified padding\n",
    "    else:\n",
    "        to_pad = arr[0] # begin or end of list\n",
    "\n",
    "    if isinstance(arr,list): # to convert a list temporarily to string\n",
    "        arr_is_list = True\n",
    "    else:\n",
    "        arr_is_list = False\n",
    "\n",
    "    if mode == 'valid':\n",
    "        pass\n",
    "\n",
    "    p_size = conv_shape//2\n",
    "    if mode == 'same':\n",
    "        if arr_is_list:\n",
    "            arr = ''.join(arr)\n",
    "        if isinstance(arr,str): #here the padding is applied\n",
    "            if pad_dir == 'center':\n",
    "                arr = to_pad*p_size+arr+to_pad*p_size\n",
    "            if pad_dir == 'left':\n",
    "                arr = to_pad*(conv_shape-1)+arr\n",
    "            if pad_dir == 'right':\n",
    "                arr = arr+to_pad*(conv_shape-1)\n",
    "        else:\n",
    "            return 'only string and list supported'\n",
    "        if arr_is_list:\n",
    "            arr = list(arr)\n",
    "\n",
    "    if conv_shape % 2 == 1: # odd conv_shape\n",
    "        return [arr[i-p_size:i+p_size+1] for i in range(p_size,len(arr)-p_size)]\n",
    "    else: # even conv_shape\n",
    "        return [arr[i:i+conv_shape] for i in range(0,len(arr)-conv_shape+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert conv1d(\"12345\",3,mode='valid' == ['123', '234', '345'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv2d(arr,conv_shape,mode='valid',padding=None,pad_dir='center') ->list:\n",
    "    \"\"\"\n",
    "    Returns a list of kernel views of a string or list \n",
    "    mode == 'valid': returns only results where the kernel fits\n",
    "    mode == 'same': return the same amount of items as original\n",
    "    when mode =='same', default padding is the outer value\n",
    "    \"\"\"\n",
    "    if padding:\n",
    "        to_pad = padding # user specified padding\n",
    "    else:\n",
    "        to_pad = arr[0] # begin or end of list\n",
    "\n",
    "    if isinstance(arr,list) or isinstance(arr,np.ndarray): # to convert a list to numpy array\n",
    "        arr_is_list = True\n",
    "    else:\n",
    "        arr_is_list = False\n",
    "\n",
    "    if mode == 'valid':\n",
    "        pass\n",
    "\n",
    "    p_size = conv_shape//2\n",
    "    if mode == 'same':\n",
    "        if arr_is_list:\n",
    "            arr = np.array(arr)\n",
    "        if isinstance(arr,str): #here the padding is applied\n",
    "            if pad_dir == 'center':\n",
    "                arr = to_pad*p_size+arr+to_pad*p_size\n",
    "            if pad_dir == 'left':\n",
    "                arr = to_pad*(conv_shape-1)+arr\n",
    "            if pad_dir == 'right':\n",
    "                arr = arr+to_pad*(conv_shape-1)\n",
    "        else:\n",
    "            return 'only string and list supported'\n",
    "        if arr_is_list:\n",
    "            arr = list(arr)\n",
    "\n",
    "    if conv_shape % 2 == 1: # odd conv_shape\n",
    "        return [arr[i-p_size:i+p_size+1] for i in range(p_size,len(arr)-p_size)]\n",
    "    else: # even conv_shape\n",
    "        return [arr[i:i+conv_shape] for i in range(0,len(arr)-conv_shape+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(np.array([np.arange(9).reshape(3,3)]), conv_shape=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific algo's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def binarysearch(minim,maxim,function, flips_to_true=True): \n",
    "    \"\"\"\n",
    "     function needs to return a boolean whether the solution is ok\n",
    "     this implementation is for function that starts with false for minim and flip to true\n",
    "     for TTTTFFFF, pass set flips_to_true flag to false. This flag is important to set correct!\n",
    "    \"\"\"\n",
    "    new = minim\n",
    "    while True:\n",
    "        new = (minim+maxim)//2\n",
    "        print(f'to_test: {new}, min {minim}, max {maxim} ', end=' ')\n",
    "        res = function(new)\n",
    "        print('function returns', res)\n",
    "        if not flips_to_true: res = not res\n",
    "        if res:\n",
    "            if new == maxim: # solution found\n",
    "                if flips_to_true:\n",
    "                    print('solution found',new)\n",
    "                    return new\n",
    "                else:\n",
    "                    print('solution found',new-1)\n",
    "                    return new-1\n",
    "            maxim = new\n",
    "        else: minim = new+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_test: 100, min 0, max 200  function returns True\nto_test: 50, min 0, max 100  function returns False\nto_test: 75, min 51, max 100  function returns True\nto_test: 63, min 51, max 75  function returns True\nto_test: 57, min 51, max 63  function returns True\nto_test: 54, min 51, max 57  function returns True\nto_test: 52, min 51, max 54  function returns True\nto_test: 51, min 51, max 52  function returns True\nto_test: 51, min 51, max 51  function returns True\nsolution found 51\n"
     ]
    }
   ],
   "source": [
    "assert binarysearch(0,200, lambda x: x > 50) == 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_test: 100, min 0, max 200  function returns False\nto_test: 50, min 0, max 100  function returns False\nto_test: 25, min 0, max 50  function returns True\nto_test: 38, min 26, max 50  function returns True\nto_test: 44, min 39, max 50  function returns True\nto_test: 47, min 45, max 50  function returns True\nto_test: 49, min 48, max 50  function returns True\nto_test: 50, min 50, max 50  function returns False\nsolution found 49\n"
     ]
    }
   ],
   "source": [
    "assert binarysearch(0,200, lambda x: x < 50, flips_to_true=False) == 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def deduce_matches(input_dict, option_type=str):\n",
    "    \"\"\"\n",
    "    Takes a dict with multiple keys that have one or more options\n",
    "    The trick is to start with what you know: keys with one option and remove that option for the other keys\n",
    "    Continuing that process leads to every key ending up with one option (hopefully)\n",
    "\n",
    "    Assumes: the options are strings and sort in some kind of container\n",
    "    \"\"\"\n",
    "    found = 0\n",
    "    while found < len(input_dict):\n",
    "        for k, v in input_dict.items():\n",
    "            if not isinstance(v, option_type) and len(v) == 1: # found one\n",
    "                to_rem = v.pop()\n",
    "                input_dict[k] = to_rem\n",
    "                found += 1\n",
    "                for _ , v2 in input_dict.items(): # remove the item from other lists\n",
    "                    if not isinstance(v2, option_type) and to_rem in v2:\n",
    "                        v2.remove(to_rem)\n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maze algo's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bfs(connections, start, goal=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Requires a connections dict with tuples with neighbors per node.\n",
    "    Or a connections function returning neighbors per node\n",
    "\n",
    "    Returns\n",
    "    if goal == None:    return dict of locations with neighbor closest to start\n",
    "    elif goal found:    returns path to goal\n",
    "    else:               returns False\n",
    "    \"\"\"\n",
    "    seen = set() # the locations that have been explored\n",
    "    frontier = deque([start]) # the locations that still need to be visited\n",
    "    # paths = {start: [start]}\n",
    "    isfunction = callable(connections)\n",
    "    parents = {start: None}\n",
    "\n",
    "    def get_path(parents,start,goal):\n",
    "        # print(start,goals)\n",
    "        cur = goal\n",
    "        path = [cur]\n",
    "        while cur != start:\n",
    "            cur = parents[cur]\n",
    "            path.append(cur)\n",
    "        path.reverse()\n",
    "        return path\n",
    "\n",
    "    while frontier:\n",
    "        search = frontier.popleft()\n",
    "        if isfunction: neighbors = connections(search)\n",
    "        else: neighbors = connections.get(search,None)\n",
    "        if neighbors:\n",
    "            for n in neighbors:\n",
    "                if n not in seen:\n",
    "                    seen.add(n)\n",
    "                    frontier.append(n)\n",
    "                    # paths[n] = paths[search]+[n]\n",
    "                    parents[n]= search\n",
    "                    if goal and n == goal:\n",
    "                        # print('goal found')\n",
    "                        return get_path(parents,start,goal)\n",
    "                        # return paths[goal],parents\n",
    "        seen.add(search)\n",
    "    if goal: return False\n",
    "    else: return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_bfs(input):\n",
    "    if input < 0: return (0,)\n",
    "    elif input > 25: return (25,)\n",
    "    else:\n",
    "        return (input-1, input+1, input + 20, input -20)\n",
    "bfs(test_bfs, 0,goal=10) == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dijkstra(connections,start, goal=None):\n",
    "    \"\"\"\n",
    "    Requires a dict with as values a LIST of tuples (neighbor, weight)\n",
    "    Or a function returning a list of tuples with neighbors and weights per node\n",
    "\n",
    "    Returns\n",
    "    if goal == None:    return all paths from start\n",
    "    elif goal found:    returns path to goal\n",
    "    else:               returns False\n",
    "    \"\"\"\n",
    "    seen = set() # the locations that have been explored\n",
    "    frontier = [(0,start)] # the locations that still need to be visited\n",
    "    isfunction = callable(connections)\n",
    "    parents = {start: (None,0)}\n",
    "\n",
    "    def get_path(parents):\n",
    "        cur = goal\n",
    "        path = [cur]\n",
    "        cost = parents[cur][1]\n",
    "        while cur != start:\n",
    "            cur = parents[cur][0]\n",
    "            path.append(cur)\n",
    "        path.reverse()\n",
    "        return path,cost\n",
    "\n",
    "    while frontier:\n",
    "        # print('\\n\\n',frontier,'\\n',parents)\n",
    "        search_cost, search_node = heapq.heappop(frontier)\n",
    "        # print('looking for', search_node,search_cost)\n",
    "        if search_node == goal: break\n",
    "        if isfunction: neighbors = connections(search_node)\n",
    "        else: neighbors = connections.get(search_node,None)\n",
    "        if neighbors:\n",
    "            for n in neighbors:\n",
    "                # print('n',n)\n",
    "                if n[0] not in parents or n[1]+ search_cost < parents[n[0]][1]:\n",
    "                    # print('updating')\n",
    "                    heapq.heappush(frontier,(search_cost+n[1],n[0]))\n",
    "                    # paths[n] = paths[search_node]+[n]\n",
    "                    parents[n[0]]= (search_node,search_cost+n[1])\n",
    "                        # return paths[goal],parents\n",
    "        seen.add(search_node)\n",
    "    if not goal: return parents\n",
    "    elif goal in parents: return get_path(parents)\n",
    "    else: return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {1:[(2,1),(5,5)],\n",
    "            2:[(1,1),(3,1)],\n",
    "            3:[(2,1),(10,10)],\n",
    "            5:[(1,1),(10,1)],\n",
    "            10:[(3,1),(5,1)]\n",
    "            }\n",
    "assert dijkstra(test_dict, 1,goal=10) == ([1, 5, 10], 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_path(parents,start,goal):\n",
    "    # print(start,goals)\n",
    "    cur = goal\n",
    "    path = [cur]\n",
    "    while cur != start:\n",
    "        cur = parents[cur]\n",
    "        path.append(cur)\n",
    "    path.reverse()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# found this on internet\n",
    "def dfs(graph, start):\n",
    "    visited, stack = set(), [start]\n",
    "    while stack:\n",
    "        vertex = stack.pop()\n",
    "        if vertex not in visited:\n",
    "            visited.add(vertex)\n",
    "            stack.extend(graph[vertex] - visited)\n",
    "    return visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_pattern_in_iter(start_pattern, function, goal = None, n_iter=1000000000):\n",
    "    \"\"\"\n",
    "        Returns when a SPECIFIED pattern has been found from a function\n",
    "        If goal = None, then first time the start pattern shows up again is returned\n",
    "    \"\"\"\n",
    "    if not goal: goal = start_pattern\n",
    "    current = start_pattern\n",
    "    for i in range(1,n_iter):\n",
    "        current = function(current)\n",
    "        # print(current)\n",
    "        if current == goal:\n",
    "            print('found at step',i, current)\n",
    "            return i, current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_repeat(start_pattern, function, n_iter=None):\n",
    "    \"\"\"\n",
    "        Returns when a NONSPECFIED repeating pattern has been found\n",
    "    \"\"\"\n",
    "    if not n_iter: n_iter = round(10e20)\n",
    "    seen = {start_pattern}\n",
    "    current = start_pattern\n",
    "    for i in range(1,n_iter):\n",
    "        current = function(current)\n",
    "        # print(current)\n",
    "        if current in seen:\n",
    "            print('found at step',i,current)\n",
    "            return i,current\n",
    "        seen.add(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_cycle(start_pattern, function):\n",
    "    \"\"\"\n",
    "        Find cycle length of some repeating pattern, by first inspecting which item repeats when\n",
    "        And subtracting the time the item was first seen\n",
    "    \"\"\"\n",
    "    step_second, pattern = find_repeat(start_pattern, function)\n",
    "    step_first, pattern = find_pattern_in_iter(pattern, Test_gen(), goal = pattern)\n",
    "    return step_second - step_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "class Test_gen():\n",
    "    def __init__(self):\n",
    "        self.results = iter([5,10,15,5,99,10])\n",
    "    def __call__(self,*args):\n",
    "        return next(self.results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found at step 5 99\nfound at step 2 10\nfound at step 1 5\nfound at step 4 5\n"
     ]
    }
   ],
   "source": [
    "assert find_pattern_in_iter(99,Test_gen(),n_iter=10) == (5,99)\n",
    "assert find_pattern_in_iter(99,Test_gen(),goal=10, n_iter=10) == (2,10)\n",
    "assert find_pattern_in_iter(99,Test_gen(),goal=5, n_iter=10) == (1,5)\n",
    "assert find_repeat(99,Test_gen(),n_iter=10) == (4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def factors(n):\n",
    "    \"\"\"\n",
    "     return set of divisors of a number\n",
    "    \"\"\"\n",
    "\n",
    "    step = 2 if n%2 else 1\n",
    "    return set(reduce(list.__add__,\n",
    "                ([i, n//i] for i in range(1, int(sqrt(n))+1, step) if n % i == 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert factors(20) == {1, 2, 4, 5, 10, 20}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gcd(a,b):\n",
    "    largest = max(a,b)\n",
    "    smallest = min(a,b)\n",
    "    while True:\n",
    "        rest = largest % smallest\n",
    "        if rest == 0:\n",
    "            return prevrest\n",
    "        else:\n",
    "            prevrest = rest\n",
    "            largest = smallest\n",
    "            smallest = rest\n",
    "\n",
    "def lcm(a):\n",
    "    lcm = a[0]\n",
    "    for i in a[1:]:\n",
    "        lcm = lcm*i//gcd(lcm, i)\n",
    "    return lcm\n",
    "lcm([4,6,7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,8,8,8,2,3]\n",
    "a.index(8)\n",
    "len(a) - 1 - a[::-1].index(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 9\nb 6\na 81\nb 3\nres 81\na 6561\nb 1\nres 531441\na 43046721\nb 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "531441"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def power(a,b,M=None):\n",
    "    # computes a**b. Actually python pow does this with optional third argument\n",
    "    res = 1\n",
    "    while(b):\n",
    "        if b % 2 == 1: \n",
    "            res = (res * a) % M if M else res * a\n",
    "            print('res',res)\n",
    "        a *= a\n",
    "        print('a',a)\n",
    "        b //= 2\n",
    "        print('b',b)\n",
    "    return res\n",
    "power(3,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_context_free_grammar.ipynb.\n",
      "Converted 02_norvig.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted 00_core.ipynb.\n",
      "Converted 01_context_free_grammar.ipynb.\n",
      "Converted 02_norvig.ipynb.\n",
      "Converted index.ipynb.\n",
      "converting: d:\\Documenten\\GitHub\\adventofcode\\aocutils\\00_core.ipynb\n",
      "converting: d:\\Documenten\\GitHub\\adventofcode\\aocutils\\01_context_free_grammar.ipynb\n",
      "converting: d:\\Documenten\\GitHub\\adventofcode\\aocutils\\02_norvig.ipynb\n",
      "converting: d:\\Documenten\\GitHub\\adventofcode\\aocutils\\index.ipynb\n",
      "converting d:\\Documenten\\GitHub\\adventofcode\\aocutils\\index.ipynb to README.md\n",
      "[main 47c0ec4] change future upwards\n",
      " 3 files changed, 14 insertions(+), 7 deletions(-)\n",
      "To https://github.com/jvanelteren/aocutils.git\n",
      "   68e7b8a..47c0ec4  main -> main\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; \n",
    "notebook2script()\n",
    "!nbdev_build_lib\n",
    "!nbdev_build_docs\n",
    "!nbdev_clean_nbs\n",
    "!git add .\n",
    "!git commit -am \"change future upwards\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd0ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}